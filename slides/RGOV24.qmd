---
title: "Wrangling Data with DuckDB"
author: "Will Angel"
date: "2024-10-23"
location: "RGOV24"
format:
  revealjs: 
    theme: blood
incremental: true

editor: visual
---


## Key Takeaways
1. DuckDB is a *very* fast in-process database.
2. Duckplyr is a package for using Dplyer on DuckDB
3. You can use Duckplyr as a *drop in replacement to get a 10-20x speedup for dplyr code*

## Agenda
* What is DuckDB
* Why should you care about DuckDB
* When should you use DuckDB
* How can you use DuckDB
* What is Duckplyr
* Data processing performance and profiling


# DuckDB?

## What is DuckDB?

DuckDB is an open source fast in-process analytical database!

* Open Source: Free & Open
* Fast: Performant. **Quickly and efficiently runs analytical SQL queries**. Speed means cheaper if you're doing cloud processing.
* In-process: **Runs locally** without a server, like SQLite.
* Analytical: DuckDB is optimized for **fast aggregations** and analytical queries to support online analytical processing (OLAP). DuckDB supports ACID transactions, but is not as fast for online transaction processing (OLTP) workloads.
* Database: DuckDB can be used to efficiently store relational data.
--TODO: fix formatting and font size

## Why you should care!
* DuckDB is a great tool for local SQL analysis. Import a file and you can do SQL locally!
* DuckDB is starting to power the next generation of embedding analytical tools, so expect browser based data filtering tools to get more powerful. 

## Why you should care (more technical)
* DuckDB is like SQLite but for data processing. You can crunch significant amounts of data locally without spinning up a full database / data warehouse server, which may create significant time/cost savings and simplify system design.
* DuckDB is versatile and fast for data processing. Competitive with spark/polars in benchmarks
* DuckDB is portable with zero dependencies.

##  When should you use DuckDB
* You should use DuckDB for data processing!
* You have medium largish data
* You don't want the hassle of procuring databricks

##  How can you use DuckDB
* Directly use the DuckDB package.
* use DBplyr to connect to a local DuckDB database
* use Duckplyr!


## What is Duckplyr
* Duckplyr is a drop in replacement for Dplyr!
* Duckplyr uses DuckDB’s “relational” API to skip the SQL and directly construct logical query plans.
* This means you can speed up your Dplyr code by ~10-20x by simply changing the package! 
* Out of memory processing!
* Unsupported operations will fall back to Dplyr, so your code will always run!

```
install.packages("duckplyr")
```

##  Data processing performance and profiling

* DuckDB:
	* versus dplyer
	* versus dbplyer
	* versus data.frame
	* versus tibbles
	* versus data.table
	* versus polars



---


<!-- Profiling:

1, 10 mb 100mb, 1G, 10G, 50G

Sensor data?


Arrow usage in R? 

Memory usage of R -->




